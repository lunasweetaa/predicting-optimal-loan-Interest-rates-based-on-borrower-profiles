# -*- coding: utf-8 -*-
"""Final Project_Luna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17rq4vzz_Y8PWqcqNUeS_jeYE_pLJCAnC

# **1. Import Library**
"""

!pip uninstall -y scikit-learn xgboost
!pip install scikit-learn==1.2.2 xgboost==1.7.6

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats.mstats import winsorize
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

"""# **2. Load Data**"""

from google.colab import drive
drive.mount('/content/drive')

loan_data = pd.read_csv('/content/drive/MyDrive/FinproDS28 - Luna Sweeta Anastasya Pangaribuan/Dataset/loan_data.csv')
loan_data.head()

"""## **2.1. About Data**

**credit.policy**: Data yang menunjukkan apakah peminjam memenuhi kriteria peminjaman LendingClub.com.

**purpose**: Data yang menunjukkan tujuan dari pinjaman peminjam.

**int.rate**: Tingkat bunga pinjaman dalam bentuk proporsi.

**installment**: Jumlah cicilan bulanan yang harus dibayar peminjam jika pinjaman disetujui.

**log.annual.inc**: Logaritma natural dari penghasilan tahunan yang dilaporkan peminjam.

**dti**: Rasio utang terhadap penghasilan peminjam.

**fico**: Skor kredit FICO peminjam yang mencerminkan kelayakan kredit.

**days.with.cr.line**: Jumlah hari peminjam telah memiliki jalur kredit aktif.

**revol.bal**: Saldo kredit bergulir yang belum dibayar oleh peminjam.

**revol.util**: Rasio penggunaan jalur kredit bergulir peminjam terhadap total kredit yang tersedia.

**inq.last.6mths**: Jumlah permintaan kredit yang dilakukan kreditur terhadap peminjam dalam 6 bulan terakhir.

**delinq.2yrs**: Jumlah keterlambatan pembayaran lebih dari 30 hari dalam 2 tahun terakhir.

**pub.rec**: Jumlah catatan publik negatif peminjam, seperti kebangkrutan atau hak gadai pajak.

**not.fully.paid**: Data yang menunjukkan apakah pinjaman dilunasi sepenuhnya oleh peminjam.

### Check Missing Value and Data Type
"""

loan_data.info()

"""Berdasarkan output diatas, dataset tidak memiliki data yang null ataupun memiliki tipe data yang tidak sesuai, namun untuk menghindari adanya data yang berisi nilai "NaN" "whitespace", etc maka dilakukan pengecekan nilai unik dari masing-masing kolom"""

# Cek Nilai Unik pada Kolom
for column in loan_data.columns:
    unique_values = loan_data[column].unique()
    print(f"Kolom: {column}")
    print(f"Jumlah Nilai Unik: {len(unique_values)}")
    print(f"Nilai Unik: {unique_values}\n")

"""Tidak terdapat keanehan pada datanya, sehingga dapat disimpulkan tidak ada data yang missing atau aneh

### Check Duplicate
"""

# Cek Duplicate Data
loan_data.duplicated().sum()

"""Tidak ada data yang duplikat!

### Check Outliers
"""

# Cek Outliers
plt.figure(figsize=(20,20))

# plotting
features = ['credit.policy', 'int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util', 'inq.last.6mths', 'delinq.2yrs', 'pub.rec', 'not.fully.paid']
for i in range(0, len(features)):
    plt.subplot(5, len(features)//3, i + 1)
    sns.boxplot(y=loan_data[features[i]], color='pink')
    plt.tight_layout()

"""Terdapat beberapa data yang outliers,seperti:  yang dimana nantinya akan dilakukan handling pada data train yang dilakukan pada bagian "Pre-processing Data"

## **2.2. Splitting Data**
"""

# Split dataset menjadi Train (60%), Validation (20%), dan Test (20%)
train_ld, temp_ld = train_test_split(loan_data, test_size=0.4, random_state=42, stratify=loan_data['not.fully.paid'])
val_ld, test_ld = train_test_split(temp_ld, test_size=0.5, random_state=42, stratify=temp_ld['not.fully.paid'])

# Cek ukuran dataset setelah split
print(f"Train set size: {train_ld.shape}")
print(f"Validation set size: {val_ld.shape}")
print(f"Test set size: {test_ld.shape}")

"""# **3. Exploratory Data Analysis**"""

# pisahkan kolom numerik dan kategorikal agar mempermudah proses EDA
numerical_columns = train_ld.select_dtypes(include=['int64', 'float64']).columns
categorical_columns = train_ld.select_dtypes(include=['object']).columns

"""## **3.1. Statistical Summary**"""

# Statistik untuk Data Numerik pada Training Set
numerical_summary_train = train_ld[numerical_columns].describe()
numerical_summary_train

"""***Insight***

1. Mayoritas peminjam memiliki skor kredit yang baik (~710), tetapi ada juga yang memiliki skor rendah (<650), yang berisiko lebih tinggi.
2. Beberapa peminjam memiliki tingkat pemanfaatan kredit sangat tinggi (>90%), yang bisa menjadi indikasi potensi gagal bayar.
3. Sebagian besar peminjam melunasi pinjaman mereka, tetapi 16% masih memiliki pinjaman yang belum lunas.
4. Ada perbedaan besar dalam jumlah cicilan dan pemanfaatan kredit, menunjukkan bahwa peminjam berasal dari berbagai latar belakang keuangan.
"""

# Statistik untuk Data kategori pada Training Set
numerical_summary_train_2 = train_ld[categorical_columns].describe()
numerical_summary_train_2

"""***Insight***

1. Mayoritas peminjam menggunakan pinjaman untuk menggabungkan atau melunasi utang sebelumnya, yang menunjukkan adanya kebutuhan besar untuk mengelola beban utang.
2. Kategori pinjaman lainnya lebih jarang dibandingkan debt consolidation, sehingga bisa menjadi pertimbangan dalam analisis suku bunga—apakah pinjaman untuk debt consolidation memiliki suku bunga lebih tinggi atau lebih rendah dibandingkan kategori lain?

## **3.2. Univariate Analysis**
"""

# Visualisasi distribusi semua fitur numerik
fig, axes = plt.subplots(nrows=len(numerical_columns), ncols=1, figsize=(10, 4 * len(numerical_columns)))

for i, col in enumerate(numerical_columns):
    sns.histplot(train_ld[col], bins=30, kde=True, ax=axes[i], color='blue')
    axes[i].set_title(f"Distribusi {col}")
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Frekuensi")

plt.tight_layout()
plt.show()

"""***Insight***

1. Distribusi Normal (Bentuk Simetris)
- int.rate (Suku Bunga Pinjaman) → Hampir normal, dengan beberapa outlier di suku bunga tinggi.
- log.annual.inc (Log Pendapatan Tahunan) → Distribusi sangat normal, dengan mean sekitar 10.9 (setara dengan ~$55,000 per tahun).
- fico (Skor Kredit FICO) → Hampir normal, tetapi sedikit condong ke kiri (banyak peminjam dengan skor di sekitar 700-750).


2. Distribusi Positively Skewed (Condong ke Kanan)
- days.with.cr.line (Lama Memiliki Jalur Kredit) → Sebagian besar peminjam memiliki jalur kredit 5-16 tahun, tetapi ada yang sangat panjang (hingga 48 tahun).
- revol.bal (Saldo Kredit Bergulir) → Mayoritas peminjam memiliki saldo kecil, tetapi ada beberapa dengan saldo sangat tinggi (~$1,2 juta).
- inq.last.6mths (Jumlah Permintaan Kredit dalam 6 Bulan Terakhir) → Sebagian besar peminjam hanya memiliki 0-2 permintaan kredit, tetapi ada yang melakukan >10 kali permintaan.
- delinq.2yrs (Jumlah Keterlambatan Pembayaran dalam 2 Tahun Terakhir) → Sebagian besar peminjam tidak pernah telat, tetapi ada yang pernah telat lebih dari 10 kali.

3. Distribusi Multimodal (Beberapa Puncak)
- installment (Cicilan Bulanan) → Ada beberapa puncak, menunjukkan bahwa cicilan mungkin ditentukan berdasarkan kategori jumlah pinjaman tertentu.
- revol.util (Pemanfaatan Kredit Bergulir) → Hampir seragam, tetapi ada konsentrasi peminjam di bawah 50% pemanfaatan dan di atas 80%.


4. Distribusi Biner / Kategorikal
- credit.policy → Mayoritas memenuhi kebijakan kredit (1).
- not.fully.paid → 16% peminjam gagal bayar.
- pub.rec → Sebagian besar tidak memiliki catatan negatif, tetapi ada beberapa yang memiliki hingga 5 catatan.

5. data dti memiliki distribusi mendekati normal tetapi sedikit skewed ke kanan (positively skewed). -> Mayoritas peminjam memiliki DTI di antara 5% hingga 20%, dengan puncak sekitar 10%-15%. Ada peminjam dengan DTI sangat rendah (0%), yang berarti mereka tidak memiliki utang sama sekali.

"""

# Buat subplots berdasarkan jumlah fitur kategorikal
fig, axes = plt.subplots(nrows=len(categorical_columns), ncols=1, figsize=(10, 4 * len(categorical_columns)))

# Jika hanya ada satu fitur kategorikal, buat agar `axes` tetap bisa diakses sebagai list
if len(categorical_columns) == 1:
    axes = [axes]

for i, col in enumerate(categorical_columns):
    sns.countplot(x=train_ld[col], order=train_ld[col].value_counts().index, ax=axes[i], color="blue")

    axes[i].set_title(f"Distribusi {col}")
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Frekuensi")

plt.tight_layout()
plt.show()

"""***Insight***

Berdasarkan histogram yang ditampilkan, purpose adalah variabel kategorikal dengan distribusi skewed (condong ke kiri) karena ada satu kategori dominan ("debt_consolidation") dengan jumlah yang jauh lebih besar dibandingkan kategori lainnya.

## **3.3. Multivariate Analysis**

Analisis Hubungan Data Numerik dengan int.rate (Scatter Plot)
"""

# Scatterplot semua fitur numerik terhadap Interest Rate (int.rate)
num_cols = [col for col in numerical_columns if col != "int.rate"]  # Exclude target variable

fig, axes = plt.subplots(nrows=len(num_cols)//3 + 1, ncols=3, figsize=(15, 20))

for i, col in enumerate(num_cols):
    row, col_index = i // 3, i % 3
    sns.scatterplot(x=train_ld[col], y=train_ld["int.rate"], alpha=0.5, ax=axes[row, col_index])
    axes[row, col_index].set_title(f"{col} vs. Interest Rate")
    axes[row, col_index].set_xlabel(col)
    axes[row, col_index].set_ylabel("Interest Rate")

# Hapus subplot kosong jika jumlah fitur numerik tidak habis dibagi 3
for j in range(i + 1, len(axes.flatten())):
    fig.delaxes(axes.flatten()[j])

plt.tight_layout()
plt.show()

"""***Insight***

1. credit.policy vs Interest Rate
  - Distribusi biner → Tidak ada korelasi langsung antara memenuhi kebijakan kredit (1) dan suku bunga.
  - Peminjam yang tidak memenuhi kebijakan kredit (0) juga mendapatkan suku bunga yang bervariasi.

2. installment vs Interest Rate
  - Tidak ada hubungan linear yang jelas → Cicilan bulanan tersebar di semua level suku bunga.
  - Namun, cicilan lebih besar cenderung memiliki variasi interest rate yang lebih luas.

3. log.annual.inc vs Interest Rate
  - Tidak ada korelasi signifikan → Interest rate tersebar di semua level pendapatan.
  - Bahkan peminjam dengan pendapatan tinggi masih bisa mendapatkan suku bunga tinggi.

4. dti (Debt-to-Income Ratio) vs Interest Rate
  - Sebaran merata tanpa tren yang jelas → Tidak ada hubungan kuat antara DTI dan interest rate.
  - Beberapa peminjam dengan DTI tinggi (>25%) masih mendapatkan suku bunga rendah.

5. fico (Skor Kredit) vs Interest Rate
  - Hubungan negatif yang kuat → Semakin tinggi skor FICO, semakin rendah suku bunga.
  - Peminjam dengan FICO >750 hampir selalu mendapatkan suku bunga lebih rendah dari 12%, sedangkan yang memiliki FICO <650 sering mendapatkan suku bunga di atas 15%.

6. days.with.cr.line (Lama Memiliki Jalur Kredit) vs Interest Rate
  - Tidak ada pola hubungan yang jelas → Peminjam dengan jalur kredit lebih lama tidak selalu mendapatkan suku bunga lebih rendah.
  - Ada peminjam dengan jalur kredit panjang tetapi masih dikenakan suku bunga tinggi.

7. revol.bal (Saldo Kredit Bergulir) vs Interest Rate
  - Tidak ada korelasi yang jelas, tetapi peminjam dengan saldo kredit besar (>500.000) lebih jarang muncul di interest rate rendah.
  - Sebagian besar peminjam memiliki saldo kredit bergulir di bawah 100.000.

8. revol.util (Pemanfaatan Kredit Bergulir) vs Interest Rate
  - Peminjam dengan pemanfaatan kredit tinggi (80%-100%) cenderung memiliki suku bunga yang lebih tinggi.
  - Namun, masih ada variasi besar, artinya pemanfaatan kredit bukan satu-satunya faktor penentu interest rate.

9. inq.last.6mths (Jumlah Permintaan Kredit dalam 6 Bulan Terakhir) vs Interest Rate
  - Peminjam yang sering mengajukan kredit (>5 kali) cenderung mendapatkan suku bunga lebih tinggi.
  - Namun, masih ada peminjam dengan sedikit permintaan kredit yang tetap memiliki suku bunga tinggi.

10. delinq.2yrs (Keterlambatan Pembayaran dalam 2 Tahun Terakhir) vs Interest Rate
  - Mayoritas peminjam tidak memiliki keterlambatan pembayaran sebelumnya.
  - Namun, peminjam yang pernah terlambat lebih dari 5 kali cenderung mendapatkan suku bunga lebih tinggi.

11. pub.rec (Catatan Publik Negatif) vs Interest Rate
  - Mayoritas peminjam tidak memiliki catatan negatif, tetapi ada beberapa dengan hingga 5 catatan negatif.
  - Tidak ada pola hubungan yang sangat jelas, meskipun peminjam dengan lebih banyak catatan publik negatif cenderung memiliki suku bunga lebih tinggi.

12. not.fully.paid (Status Pelunasan Pinjaman) vs Interest Rate
  - Peminjam yang tidak melunasi pinjaman (not.fully.paid = 1) cenderung memiliki suku bunga lebih tinggi.
  - Semakin tinggi suku bunga, kemungkinan gagal bayar juga meningkat.

Analisis Hubungan Data Kategorikal dengan int.rate (Bar Plot)
"""

# Buat subplots berdasarkan jumlah fitur kategorikal
fig, axes = plt.subplots(nrows=len(categorical_columns), ncols=1, figsize=(10, 4 * len(categorical_columns)))

# Jika hanya ada satu fitur kategorikal, tetap gunakan list agar tidak error
if len(categorical_columns) == 1:
    axes = [axes]

# Loop untuk setiap fitur kategorikal
for i, col in enumerate(categorical_columns):
    sns.barplot(x=train_ld[col],
                y=train_ld['int.rate'],
                ax=axes[i],
                errorbar=None,   # Mengganti `ci=None` dengan `errorbar=None`
                hue=train_ld[col],  # Menambahkan `hue` agar palette tetap berlaku
                legend=False)   # Menghapus legend agar tidak berlebihan

    axes[i].set_title(f"Rata-rata Int. Rate berdasarkan {col}", fontsize=12)
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Rata-rata Int. Rate")
    axes[i].tick_params(axis='x', rotation=45)  # Rotasi jika kategori panjang

# Menyesuaikan tata letak agar tidak bertumpuk
plt.tight_layout()
plt.show()

"""***Insight***

1. Pinjaman untuk bisnis kecil ("small_business") memiliki rata-rata interest rate tertinggi, mungkin karena risiko bisnis lebih tinggi.
2. Debt Consolidation dan Credit Card juga memiliki interest rate yang cukup tinggi, yang bisa menunjukkan bahwa peminjam ini sudah memiliki utang sebelumnya dan berisiko lebih tinggi.
3. Major Purchase dan Home Improvement memiliki interest rate lebih rendah, karena cenderung lebih stabil dan berorientasi pada aset.
4. Peminjaman untuk pendidikan memiliki suku bunga yang relatif moderat, menunjukkan prospek penghasilan yang lebih baik di masa depan.

Analisis Korelasi Antar Data Numerik (Heatmap)
"""

# Menghitung matriks korelasi
correlation_matrix = train_ld[numerical_columns].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, mask=np.triu(correlation_matrix))
plt.title("Heatmap Korelasi Antar Data Numerik", fontsize=14)
plt.show()

"""***Insight***

1. fico memiliki korelasi negatif kuat dengan int.rate (-0.71) -> Semakin tinggi skor kredit FICO, semakin rendah interest rate yang diberikan.
2. revol.util memiliki korelasi positif moderat dengan int.rate (0.47) -> Semakin tinggi penggunaan kredit bergulir (revol.util), semakin tinggi interest rate.
3. installment memiliki korelasi positif (0.27) dengan int.rate -> Semakin besar cicilan bulanan (installment), semakin tinggi interest rate.
4. inq.last.6mths (jumlah permintaan kredit dalam 6 bulan) memiliki korelasi positif dengan int.rate (0.20) -> Semakin sering peminjam mengajukan kredit dalam waktu singkat, semakin tinggi interest rate.
5. Pendapatan (log.annual.inc) dan Debt-to-Income Ratio (dti) tidak memiliki pengaruh signifikan terhadap suku bunga.
6. Ada beberapa korelasi antar fitur yang bisa menyebabkan multikollinearitas, seperti fico dan revol.util.
7. Jumlah permintaan kredit dalam 6 bulan terakhir (inq.last.6mths) berhubungan dengan gagal bayar (not.fully.paid).

## **3.4. Deep Dive EDA**

1. Apakah peminjam di kategori tertentu (misalnya, small_business) lebih sering gagal bayar?
2. Apakah peminjam dengan penggunaan kredit tinggi lebih sering gagal bayar?
3. Apakah peminjam dengan FICO rendah & Revol Util tinggi hampir selalu mendapatkan suku bunga tinggi?
4. Bagaimana distribusi fico, dti, dan revol.util untuk peminjam yang gagal melunasi (not.fully.paid = 1) dibandingkan dengan yang melunasi sepenuhnya (not.fully.paid = 0)?
5. Bagaimana distribusi tingkat bunga untuk peminjam yang gagal melunasi?
"""

# 1. Apakah peminjam di kategori tertentu (misalnya, small_business) lebih sering gagal bayar?
fig, ax = plt.subplots(figsize=(12, 6))

# Hitung persentase gagal bayar berdasarkan purpose
purpose_default = train_ld.groupby("purpose")["not.fully.paid"].mean().sort_values(ascending=False)

# Plot bar chart
sns.barplot(x=purpose_default.index, y=purpose_default.values, ax=ax, palette="coolwarm")

# Format plot
ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
ax.set_title("Persentase Peminjam yang Gagal Bayar Berdasarkan Purpose")
ax.set_xlabel("Purpose")
ax.set_ylabel("Persentase Gagal Bayar")

plt.tight_layout()
plt.show()

# 2. Apakah peminjam dengan penggunaan kredit tinggi lebih sering gagal bayar?
fig, ax = plt.subplots(figsize=(10, 6))

# Binning revol.util ke dalam kategori
revol_util_bins = pd.cut(train_ld["revol.util"], bins=[0, 30, 60, 90, 120], labels=["0-30%", "30-60%", "60-90%", "90-120%"])

# Hitung rata-rata gagal bayar per kategori
revol_util_default = train_ld.groupby(revol_util_bins, observed=False)["not.fully.paid"].mean().reset_index()

# Visualisasi
sns.barplot(x="revol.util", y="not.fully.paid", data=revol_util_default, palette="coolwarm", ax=ax)

# Format plot
ax.set_title("Persentase Peminjam Gagal Bayar Berdasarkan Revolving Utilization")
ax.set_xlabel("Revol Utilization (%)")
ax.set_ylabel("Persentase Gagal Bayar")

plt.show()

# 3. Apakah peminjam dengan FICO rendah & Revol Util tinggi hampir selalu mendapatkan suku bunga tinggi?
fig, ax = plt.subplots(figsize=(10, 6))

# Buat pivot table dengan FICO dan Revol Utilization
pivot_table = train_ld.pivot_table(
    index=pd.cut(train_ld["fico"], bins=10, include_lowest=True),
    columns=pd.cut(train_ld["revol.util"], bins=10, include_lowest=True),
    values="int.rate",
    aggfunc="mean",
    observed=False
)

# Visualisasi Heatmap
sns.heatmap(pivot_table, cmap="coolwarm", ax=ax, annot=True, fmt=".2f", linewidths=0.5)

# Format plot
ax.set_title("Heatmap Interest Rate berdasarkan FICO & Revol Utilization")
ax.set_xlabel("Revolving Utilization (%)")
ax.set_ylabel("FICO Score")

plt.show()

# 4. Boxplot FICO, DTI, dan Revol Util berdasarkan Status Pembayaran
fig, axes = plt.subplots(nrows=3, figsize=(12, 15))

# Konversi status pembayaran ke string untuk menghindari error palette
train_ld["not.fully.paid"] = train_ld["not.fully.paid"].astype(str)

# Boxplot FICO Score
sns.boxplot(data=train_ld, x="not.fully.paid", y="fico", hue="not.fully.paid", palette=["blue", "red"], ax=axes[0])
axes[0].set_title("Boxplot FICO untuk Peminjam yang Lunas vs Gagal Bayar")
axes[0].set_xlabel("Status Pembayaran")
axes[0].set_ylabel("FICO Score")
axes[0].set_xticklabels(["Lunas", "Gagal Bayar"])
axes[0].legend(title="Not Fully Paid")

# Boxplot DTI (Debt-to-Income Ratio)
sns.boxplot(data=train_ld, x="not.fully.paid", y="dti", hue="not.fully.paid", palette=["blue", "red"], ax=axes[1])
axes[1].set_title("Boxplot DTI untuk Peminjam yang Lunas vs Gagal Bayar")
axes[1].set_xlabel("Status Pembayaran")
axes[1].set_ylabel("Debt-to-Income Ratio (DTI)")
axes[1].set_xticklabels(["Lunas", "Gagal Bayar"])
axes[1].legend(title="Not Fully Paid")

# Boxplot Revolving Utilization
sns.boxplot(data=train_ld, x="not.fully.paid", y="revol.util", hue="not.fully.paid", palette=["blue", "red"], ax=axes[2])
axes[2].set_title("Boxplot Revolving Utilization untuk Peminjam yang Lunas vs Gagal Bayar")
axes[2].set_xlabel("Status Pembayaran")
axes[2].set_ylabel("Revol Utilization (%)")
axes[2].set_xticklabels(["Lunas", "Gagal Bayar"])
axes[2].legend(title="Not Fully Paid")

plt.tight_layout()
plt.show()

# Visualisasi Boxplot Interest Rate berdasarkan Status Pembayaran
plt.figure(figsize=(10, 5))
sns.boxplot(x="not.fully.paid", y="int.rate", data=train_ld, hue="not.fully.paid", palette=["blue", "red"])
plt.xticks([0, 1], ["Lunas", "Gagal Bayar"])
plt.title("Boxplot Interest Rate untuk Peminjam yang Lunas vs Gagal Bayar")
plt.xlabel("Status Pembayaran")
plt.ylabel("Interest Rate")
plt.legend(title="Not Fully Paid", labels=["Lunas", "Gagal Bayar"])
plt.show()

"""# **4. Pre-processing Data**

## **4.1 Handling Outlier**
"""

# Copy data untuk menjaga keaslian dataset
train_processed = train_ld.copy()

# Fitur yang akan diterapkan Winsorization (karena outliersnya sangat ekstrem)
winsor_features = ["int.rate", "installment", "log.annual.inc", "days.with.cr.line", "revol.bal", "inq.last.6mths", "delinq.2yrs", "pub.rec"]

# Fungsi untuk menerapkan Winsorization pada fitur numerik yang benar-benar memiliki outliers ekstrem
def apply_winsorization(df, features, limits=(0.01, 0.01)):  # 1% trimming atas & bawah
    for feature in features:
        df[feature] = winsorize(df[feature], limits=limits)  # Winsorization 1% bawah & atas
    return df

# Terapkan Winsorization pada fitur yang dipilih
train_processed = apply_winsorization(train_processed, winsor_features)

# Cek ukuran dataset sebelum dan sesudah Winsorization (seharusnya tetap sama)
print(f"Ukuran dataset sebelum Winsorization: {train_ld.shape}")
print(f"Ukuran dataset setelah Winsorization: {train_processed.shape}")

"""## **4.2 Handling Multicollinearity**"""

# Fungsi untuk menghitung VIF (Variance Inflation Factor)
def calculate_vif(df, features):
    X = df[features].copy()
    vif_data = pd.DataFrame()
    vif_data["Feature"] = X.columns
    vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    return vif_data

# Pilih fitur numerik untuk mengecek multicollinearity
numerical_features = ["installment", "log.annual.inc", "dti",
                      "days.with.cr.line", "revol.bal", "revol.util",
                      "inq.last.6mths", "delinq.2yrs", "pub.rec"]

# Hitung VIF sebelum penghapusan fitur
vif_results = calculate_vif(train_processed, numerical_features)

# Mengidentifikasi fitur dengan VIF tinggi (threshold > 10)
high_vif_features = vif_results[vif_results["VIF"] > 10]["Feature"].tolist()

# Menampilkan fitur dengan VIF tinggi
print("Fitur dengan Multicollinearity Tinggi (VIF > 10):", high_vif_features)

# Menghapus fitur dengan multicollinearity tinggi dari dataset train
train_processed.drop(columns=high_vif_features, inplace=True)

# Hitung ulang VIF setelah penghapusan fitur
vif_results_after = calculate_vif(train_processed, [col for col in numerical_features if col not in high_vif_features])

# Menampilkan hasil VIF sebelum dan sesudah penghapusan fitur
print("\n===== VIF Sebelum Penghapusan =====")
print(vif_results)

print("\n===== VIF Setelah Penghapusan =====")
print(vif_results_after)

# Pisahkan Target dan Fitur di Train, Test, dan Validation
X_train, y_train = train_processed.drop(columns=["int.rate"]), train_processed["int.rate"]
X_test, y_test = test_ld.drop(columns=["int.rate"]), test_ld["int.rate"]
X_val, y_val = val_ld.drop(columns=["int.rate"]), val_ld["int.rate"]

"""## **4.3 Encoding**"""

# Encoding hanya di Train, lalu terapkan ke Test & Validation
encoder = OneHotEncoder(sparse=False, drop="first")
X_train_encoded = encoder.fit_transform(X_train[["purpose"]])
X_test_encoded = encoder.transform(X_test[["purpose"]])
X_val_encoded = encoder.transform(X_val[["purpose"]])

# Ubah menjadi DataFrame dan gabungkan kembali
encoded_columns = encoder.get_feature_names_out(["purpose"])
X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_columns, index=X_train.index)
X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_columns, index=X_test.index)
X_val_encoded_df = pd.DataFrame(X_val_encoded, columns=encoded_columns, index=X_val.index)

# Hapus kolom 'purpose' lama dan tambahkan kolom yang sudah di-encode
X_train = pd.concat([X_train.drop(columns=["purpose"]), X_train_encoded_df], axis=1)
X_test = pd.concat([X_test.drop(columns=["purpose"]), X_test_encoded_df], axis=1)
X_val = pd.concat([X_val.drop(columns=["purpose"]), X_val_encoded_df], axis=1)

"""## **4.4 Feature Selection**"""

# Feature Selection menggunakan Mutual Information
mi_scores = mutual_info_regression(X_train, y_train)
mi_importances = pd.DataFrame({
    "Feature": X_train.columns,
    "Importance_MI": mi_scores
}).sort_values(by="Importance_MI", ascending=False)

# Pilih fitur dengan nilai Mutual Information di atas rata-rata
selected_features = mi_importances[mi_importances["Importance_MI"] > mi_importances["Importance_MI"].mean()]["Feature"].tolist()

# Terapkan seleksi fitur ke semua set
X_train = X_train[selected_features]
X_test = X_test[selected_features]
X_val = X_val[selected_features]

mi_importances

selected_features

X_train.head()

"""## **4.5 Scaling**"""

# 5. Scaling menggunakan StandardScaler (hanya di train, lalu diterapkan ke test & val)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_val_scaled = scaler.transform(X_val)

# Konversi kembali ke DataFrame dengan nama kolom yang sesuai
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)
X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)

"""# **5. Modeling**"""

# Inisialisasi model
lr = LinearRegression()
rf = RandomForestRegressor(n_estimators=100, random_state=42)
xgb = XGBRegressor(n_estimators=100, random_state=42)

# Train model
lr.fit(X_train_scaled, y_train)
rf.fit(X_train_scaled, y_train)
xgb.fit(X_train_scaled, y_train)

# Prediksi pada Validation Set
y_pred_lr_val = lr.predict(X_val_scaled)
y_pred_rf_val = rf.predict(X_val_scaled)
y_pred_xgb_val = xgb.predict(X_val_scaled)

# Evaluasi pada Validation Set
metrics_val = pd.DataFrame({
    "Model": ["Linear Regression", "Random Forest", "XGBoost"],
    "RMSE": [mean_squared_error(y_val, y_pred_lr_val, squared=False),
             mean_squared_error(y_val, y_pred_rf_val, squared=False),
             mean_squared_error(y_val, y_pred_xgb_val, squared=False)],
    "MAE": [mean_absolute_error(y_val, y_pred_lr_val),
            mean_absolute_error(y_val, y_pred_rf_val),
            mean_absolute_error(y_val, y_pred_xgb_val)],
    "R² Score": [r2_score(y_val, y_pred_lr_val),
                 r2_score(y_val, y_pred_rf_val),
                 r2_score(y_val, y_pred_xgb_val)]
})

# Prediksi pada Test Set
y_pred_lr_test = lr.predict(X_test_scaled)
y_pred_rf_test = rf.predict(X_test_scaled)
y_pred_xgb_test = xgb.predict(X_test_scaled)

# Evaluasi pada Test Set
metrics_test = pd.DataFrame({
    "Model": ["Linear Regression", "Random Forest", "XGBoost"],
    "RMSE": [mean_squared_error(y_test, y_pred_lr_test, squared=False),
             mean_squared_error(y_test, y_pred_rf_test, squared=False),
             mean_squared_error(y_test, y_pred_xgb_test, squared=False)],
    "MAE": [mean_absolute_error(y_test, y_pred_lr_test),
            mean_absolute_error(y_test, y_pred_rf_test),
            mean_absolute_error(y_test, y_pred_xgb_test)],
    "R² Score": [r2_score(y_test, y_pred_lr_test),
                 r2_score(y_test, y_pred_rf_test),
                 r2_score(y_test, y_pred_xgb_test)]
})

# Gabungkan hasil evaluasi pada Validation dan Test Set
print("\n=== Model Performance Comparison on Validation Set ===")
print(metrics_val)

print("\n=== Model Performance Comparison on Test Set ===")
print(metrics_test)

"""**Cross Validation**"""

from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd

# Model yang akan diuji
models = [LinearRegression(), RandomForestRegressor(), XGBRegressor()]

# Hasil Cross-Validation
cv_results = []

# Cross-validation pada beberapa model
for model in models:
    # Cross-validation score menggunakan neg_mean_squared_error untuk menghitung RMSE
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')

    # Evaluasi menggunakan RMSE, MAE, dan R²
    model_name = model.__class__.__name__

    model.fit(X_train_scaled, y_train)  # Melatih model untuk evaluasi lebih lanjut
    y_pred = model.predict(X_val_scaled)  # Prediksi pada validation set

    rmse = mean_squared_error(y_val, y_pred, squared=False)
    mae = mean_absolute_error(y_val, y_pred)
    r2 = r2_score(y_val, y_pred)

    # Menyimpan hasil cross-validation dan evaluasi
    cv_results.append({
        "Model": model_name,
        "Mean RMSE (CV)": (-cv_scores.mean())**0.5,
        "Validation RMSE": rmse,
        "Validation MAE": mae,
        "Validation R²": r2
    })

# Menampilkan hasil cross-validation dan evaluasi pada validation set
cv_results_df = pd.DataFrame(cv_results)
print("\n=== Cross-Validation and Evaluation on Validation Set ===")
print(cv_results_df)

"""**Hyperparameter Tuning**"""

# Hyperparameter Tuning untuk XGBoost
param_grid_xgb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 5, 10],
    'subsample': [0.8, 1.0]
}

# Hyperparameter Tuning untuk RandomForest
param_grid_rf = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5]
}

# Membuat model
xgb = XGBRegressor(random_state=42)
rf = RandomForestRegressor(random_state=42)

# Menyiapkan GridSearchCV untuk kedua model
grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error')
grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error')

# Melakukan fitting GridSearch untuk kedua model
grid_search_xgb.fit(X_train_scaled, y_train)
grid_search_rf.fit(X_train_scaled, y_train)

# Hasil dari GridSearch
best_xgb_model = grid_search_xgb.best_estimator_
best_rf_model = grid_search_rf.best_estimator_

print(f"Best Hyperparameters for XGBoost: {grid_search_xgb.best_params_}")
print(f"Best Hyperparameters for RandomForest: {grid_search_rf.best_params_}")

# Gunakan hyperparameter terbaik untuk XGBoost dan Random Forest
best_xgb_model = XGBRegressor(
    learning_rate=0.1,
    max_depth=5,
    n_estimators=200,
    subsample=0.8,
    random_state=42
)

best_rf_model = RandomForestRegressor(
    max_depth=10,
    min_samples_split=5,
    n_estimators=200,
    random_state=42
)

# Latih model dengan hyperparameter terbaik pada data training
best_xgb_model.fit(X_train_scaled, y_train)
best_rf_model.fit(X_train_scaled, y_train)

# Prediksi pada Validation Set
y_pred_xgb_val = best_xgb_model.predict(X_val_scaled)
y_pred_rf_val = best_rf_model.predict(X_val_scaled)

# Evaluasi pada Validation Set
rmse_xgb_val = mean_squared_error(y_val, y_pred_xgb_val, squared=False)
mae_xgb_val = mean_absolute_error(y_val, y_pred_xgb_val)
r2_xgb_val = r2_score(y_val, y_pred_xgb_val)

rmse_rf_val = mean_squared_error(y_val, y_pred_rf_val, squared=False)
mae_rf_val = mean_absolute_error(y_val, y_pred_rf_val)
r2_rf_val = r2_score(y_val, y_pred_rf_val)

# Prediksi pada Test Set
y_pred_xgb_test = best_xgb_model.predict(X_test_scaled)
y_pred_rf_test = best_rf_model.predict(X_test_scaled)

# Evaluasi pada Test Set
rmse_xgb_test = mean_squared_error(y_test, y_pred_xgb_test, squared=False)
mae_xgb_test = mean_absolute_error(y_test, y_pred_xgb_test)
r2_xgb_test = r2_score(y_test, y_pred_xgb_test)

rmse_rf_test = mean_squared_error(y_test, y_pred_rf_test, squared=False)
mae_rf_test = mean_absolute_error(y_test, y_pred_rf_test)
r2_rf_test = r2_score(y_test, y_pred_rf_test)

# Gabungkan hasil evaluasi Validation dan Test Set untuk kedua model
metrics_combined = pd.DataFrame({
    "Model": ["XGBoost", "Random Forest"],
    "Validation RMSE": [rmse_xgb_val, rmse_rf_val],
    "Validation MAE": [mae_xgb_val, mae_rf_val],
    "Validation R²": [r2_xgb_val, r2_rf_val],
    "Test RMSE": [rmse_xgb_test, rmse_rf_test],
    "Test MAE": [mae_xgb_test, mae_rf_test],
    "Test R²": [r2_xgb_test, r2_rf_test]
})

# Menampilkan hasil evaluasi gabungan
print("\n=== Combined Model Performance (Validation and Test Set) ===")
print(metrics_combined)

"""Berdasarkan hasil ini, XGBoost sedikit lebih unggul dibandingkan Random Forest pada kedua set (Validation dan Test). Berdasarkan hasil XGBoost yang di peroleh:

  1. RMSE: Pada Validation Set, RMSE adalah 0.014001, dan pada Test Set adalah 0.014227. Nilai ini menunjukkan bahwa kesalahan rata-rata prediksi model XGBoost relatif kecil, artinya model dapat memprediksi nilai target dengan cukup akurat. RMSE sedikit lebih tinggi pada test set, tetapi perbedaannya sangat kecil, yang menunjukkan bahwa model masih dapat menggeneralisasi dengan baik pada data yang belum pernah dilihat sebelumnya.

  2. MAE: Pada Validation Set, MAE adalah 0.009864, dan pada Test Set, MAE adalah 0.009956. Nilai MAE yang rendah menunjukkan bahwa rata-rata kesalahan prediksi model juga kecil dan konsisten, baik pada data validation maupun test.

  3. R²: Pada Validation Set, R² adalah 0.733914, dan pada Test Set, R² adalah 0.714462. Ini menunjukkan bahwa model XGBoost dapat menjelaskan sekitar 73% variasi data pada Validation Set dan 71% pada Test Set. Nilai R² ini relatif baik, menandakan bahwa model berhasil menangkap sebagian besar pola dalam data.

Secara keseluruhan, hasil evaluasi untuk XGBoost menunjukkan bahwa model ini cukup baik dalam memprediksi data, dengan RMSE dan MAE yang rendah serta R² yang cukup tinggi. Model menunjukkan kinerja yang stabil antara Validation dan Test Set, yang berarti model ini tidak overfitting dan memiliki kemampuan generalisasi yang baik.

# **6. Implementasi Model**
"""

# Fungsi untuk memprediksi interest rate berdasarkan input pengguna
def predict_interest_rate():
    # Menerima input dari pengguna
    installment = float(input("Masukkan cicilan bulanan (installment): "))
    fico = float(input("Masukkan skor kredit FICO: "))
    revol_util = float(input("Masukkan rasio penggunaan kredit bergulir (revol.util): "))

    # Membuat DataFrame untuk input baru
    input_data = pd.DataFrame([[installment, fico, revol_util]], columns=['installment', 'fico', 'revol.util'])

    # Menggunakan model untuk memprediksi interest rate
    prediction = model.predict(input_data)

    return prediction[0]

# Contoh penggunaan fungsi prediksi dengan input dari pengguna
predicted_int_rate = predict_interest_rate()
print(f'Predicted Interest Rate: {predicted_int_rate}')